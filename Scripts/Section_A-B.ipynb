{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"local[1]\") \\\n",
    "        .appName(\"Kolonskopi\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",4)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in English document 1862234\n",
      "\n",
      "Number of lines in Swedish document 1862234\n",
      "\n",
      "There are equal number of lines in the two documents\n",
      "\n",
      "Number of partitions in files:\n",
      " EN:\t2\n",
      " SV:\t3\n"
     ]
    }
   ],
   "source": [
    "en_tF = spark_context.textFile('hdfs://192.168.1.153:9000/europarl/europarl-v7.sv-en.en')\n",
    "\n",
    "en_lc = en_tF.count()\n",
    "print(f\"Number of lines in English document {en_lc}\\n\")\n",
    "\n",
    "sv_tF = spark_context.textFile('hdfs://192.168.1.153:9000/europarl/europarl-v7.sv-en.sv')\n",
    "\n",
    "sv_lc = sv_tF.count()\n",
    "print(f\"Number of lines in Swedish document {sv_lc}\\n\")\n",
    "\n",
    "if en_lc == sv_lc:\n",
    "    print(f\"There are equal number of lines in the two documents\\n\")\n",
    "\n",
    "print(f\"Number of partitions in files:\\n EN:\\t{en_tF.getNumPartitions()}\\n SV:\\t{sv_tF.getNumPartitions()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question A2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 objects in English and then Swedish file:\n",
      "\n",
      "[['resumption', 'of', 'the', 'session'], ['i', 'declare', 'resumed', 'the', 'session', 'of', 'the', 'european', 'parliament', 'adjourned', 'on', 'friday', '17', 'december', '1999,', 'and', 'i', 'would', 'like', 'once', 'again', 'to', 'wish', 'you', 'a', 'happy', 'new', 'year', 'in', 'the', 'hope', 'that', 'you', 'enjoyed', 'a', 'pleasant', 'festive', 'period.'], ['although,', 'as', 'you', 'will', 'have', 'seen,', 'the', 'dreaded', \"'millennium\", \"bug'\", 'failed', 'to', 'materialise,', 'still', 'the', 'people', 'in', 'a', 'number', 'of', 'countries', 'suffered', 'a', 'series', 'of', 'natural', 'disasters', 'that', 'truly', 'were', 'dreadful.'], ['you', 'have', 'requested', 'a', 'debate', 'on', 'this', 'subject', 'in', 'the', 'course', 'of', 'the', 'next', 'few', 'days,', 'during', 'this', 'part-session.'], ['in', 'the', 'meantime,', 'i', 'should', 'like', 'to', 'observe', 'a', \"minute'\", 's', 'silence,', 'as', 'a', 'number', 'of', 'members', 'have', 'requested,', 'on', 'behalf', 'of', 'all', 'the', 'victims', 'concerned,', 'particularly', 'those', 'of', 'the', 'terrible', 'storms,', 'in', 'the', 'various', 'countries', 'of', 'the', 'european', 'union.'], ['please', 'rise,', 'then,', 'for', 'this', \"minute'\", 's', 'silence.'], ['(the', 'house', 'rose', 'and', 'observed', 'a', \"minute'\", 's', 'silence)'], ['madam', 'president,', 'on', 'a', 'point', 'of', 'order.'], ['you', 'will', 'be', 'aware', 'from', 'the', 'press', 'and', 'television', 'that', 'there', 'have', 'been', 'a', 'number', 'of', 'bomb', 'explosions', 'and', 'killings', 'in', 'sri', 'lanka.'], ['one', 'of', 'the', 'people', 'assassinated', 'very', 'recently', 'in', 'sri', 'lanka', 'was', 'mr', 'kumar', 'ponnambalam,', 'who', 'had', 'visited', 'the', 'european', 'parliament', 'just', 'a', 'few', 'months', 'ago.']]\n",
      "[['återupptagande', 'av', 'sessionen'], ['jag', 'förklarar', 'europaparlamentets', 'session', 'återupptagen', 'efter', 'avbrottet', 'den', '17', 'december.', 'jag', 'vill', 'på', 'nytt', 'önska', 'er', 'ett', 'gott', 'nytt', 'år', 'och', 'jag', 'hoppas', 'att', 'ni', 'haft', 'en', 'trevlig', 'semester.'], ['som', 'ni', 'kunnat', 'konstatera', 'ägde', '\"den', 'stora', 'år', '2000-buggen\"', 'aldrig', 'rum.', 'däremot', 'har', 'invånarna', 'i', 'ett', 'antal', 'av', 'våra', 'medlemsländer', 'drabbats', 'av', 'naturkatastrofer', 'som', 'verkligen', 'varit', 'förskräckliga.'], ['ni', 'har', 'begärt', 'en', 'debatt', 'i', 'ämnet', 'under', 'sammanträdesperiodens', 'kommande', 'dagar.'], ['till', 'dess', 'vill', 'jag', 'att', 'vi,', 'som', 'ett', 'antal', 'kolleger', 'begärt,', 'håller', 'en', 'tyst', 'minut', 'för', 'offren', 'för', 'bl.a.', 'stormarna', 'i', 'de', 'länder', 'i', 'europeiska', 'unionen', 'som', 'drabbats.'], ['jag', 'ber', 'er', 'resa', 'er', 'för', 'en', 'tyst', 'minut.'], ['(parlamentet', 'höll', 'en', 'tyst', 'minut.)'], ['fru', 'talman!', 'det', 'gäller', 'en', 'ordningsfråga.'], ['ni', 'känner', 'till', 'från', 'media', 'att', 'det', 'skett', 'en', 'rad', 'bombexplosioner', 'och', 'mord', 'i', 'sri', 'lanka.'], ['en', 'av', 'de', 'personer', 'som', 'mycket', 'nyligen', 'mördades', 'i', 'sri', 'lanka', 'var', 'kumar', 'ponnambalam,', 'som', 'besökte', 'europaparlamentet', 'för', 'bara', 'några', 'månader', 'sedan.']]\n",
      "After pre-processing the files have the same number of lines\n"
     ]
    }
   ],
   "source": [
    "en_low_tF = en_tF.map(lambda line: line.lower().split(' ')) #split lines on spaces \n",
    "sv_low_tF = sv_tF.map(lambda line: line.lower().split(' '))\n",
    "\n",
    "print(f\"The first 10 objects in English and then Swedish file:\\n\")\n",
    "print(en_low_tF.take(10))\n",
    "print(sv_low_tF.take(10))\n",
    "\n",
    "en_low_lc = en_low_tF.count()\n",
    "sv_low_lc = sv_low_tF.count()\n",
    "\n",
    "if en_low_lc == sv_low_lc:\n",
    "    print(\"After pre-processing the files have the same number of lines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most commonly used words in English carpus, and their count:\n",
      " [('the', 3498375), ('of', 1659758), ('to', 1539760), ('and', 1288401), ('in', 1085993), ('that', 797516), ('a', 773522), ('is', 758050), ('for', 534242), ('we', 522849)]\n",
      "\n",
      "Most commonly used words in Swedish carpus, and their count:\n",
      " [('att', 1706293), ('och', 1344830), ('i', 1050774), ('det', 924866), ('som', 913276), ('för', 908680), ('av', 738068), ('är', 694381), ('en', 620310), ('vi', 539797)]\n",
      "\n",
      "Seems reasonable that articles, conjunctions, determiners and prepositions are most ocuring in texts.\n"
     ]
    }
   ],
   "source": [
    "en_words = en_low_tF.flatMap(lambda line: line)\n",
    "en_word_counts = en_words.map(lambda word: (word, 1)).reduceByKey(lambda x, y: x+y).sortBy(lambda word_count: -word_count[1]).take(10)\n",
    "\n",
    "sv_words = sv_low_tF.flatMap(lambda line: line)\n",
    "sv_word_counts = sv_words\\\n",
    "    .map(lambda word: (word, 1))\\\n",
    "    .reduceByKey(lambda x, y: x+y)\\\n",
    "    .sortBy(lambda word_count: -word_count[1])\\\n",
    "    .take(10) #tuplify word with count, aggregate word counts, sort by descending occurances.\n",
    "\n",
    "\n",
    "print(f\"Most commonly used words in English carpus, and their count:\\n {en_word_counts}\\n\\n\"\n",
    "    f\"Most commonly used words in Swedish carpus, and their count:\\n {sv_word_counts}\\n\\n\"\n",
    "    f\"Seems reasonable that articles, conjunctions, determiners and prepositions are most ocuring in texts.\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question A4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx_en_low_tF = en_low_tF\\\n",
    "    .zipWithIndex()\\\n",
    "    .map(lambda line: (line[1], line[0])) #index lines, swap key and value\n",
    "    \n",
    "indx_sv_low_tF = sv_low_tF\\\n",
    "    .zipWithIndex()\\\n",
    "    .map(lambda line: (line[1], line[0]))\n",
    "\n",
    "#Inner join keys, filter for equal length lines, randomly selected number of words to start with \n",
    "j_sv_en_indx = indx_en_low_tF\\\n",
    "    .join(indx_sv_low_tF)\\\n",
    "    .filter(lambda line: len(line[1][0]) == len(line[1][1]))\\\n",
    "    .filter(lambda line: len(line[1][0]) < 10)\\\n",
    "    .filter(lambda line: len(line[1][0]) > 0)\n",
    "\n",
    "word_pairs = j_sv_en_indx\\\n",
    "    .flatMap(lambda word_pair: list(zip(word_pair[1][0], word_pair[1][1])))\\\n",
    "    .map(lambda pair: (pair, 1))\\\n",
    "    .reduceByKey(lambda x, y: x+y)\\\n",
    "    .sortBy(lambda x: -x[1])\\\n",
    "    .take(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('is', 'är'), 10040),\n",
       " (('we', 'vi'), 5530),\n",
       " (('i', 'jag'), 5020),\n",
       " (('this', 'detta'), 3252),\n",
       " (('closed.', 'avslutad.'), 2964),\n",
       " (('and', 'och'), 2917),\n",
       " (('a', 'en'), 2888),\n",
       " (('it', 'det'), 2866),\n",
       " (('that', 'det'), 2806),\n",
       " (('not', 'inte'), 2650),\n",
       " (('(applause)', '(applåder)'), 2548),\n",
       " (('', '.'), 2223),\n",
       " (('.', '.'), 2143),\n",
       " (('have', 'har'), 1967),\n",
       " (('in', 'i'), 1932),\n",
       " (('will', 'att'), 1920),\n",
       " (('a', 'ett'), 1872),\n",
       " (('are', 'är'), 1789),\n",
       " (('the', 'omröstningen'), 1778),\n",
       " (('vote', 'kommer'), 1727)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After mixing around a bit, I found that a line length of 1-9 words gave reasonable translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import UDFRegistration\n",
    "\n",
    "\n",
    "sqlContext = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"local[1]\") \\\n",
    "        .appName(\"Kolonskopi\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",4)\\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sqlContext\\\n",
    "    .read.option(\"header\",\"true\")\\\n",
    "    .csv(\"hdfs://192.168.1.153:9000/parking-citations.csv\")\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+----------+\n",
      "|Ticket number|         Issue Date|Issue time|Meter Id|Marked Time|RP State Plate|Plate Expiry Date| VIN|Make|Body Style|Color|            Location|Route|Agency|Violation code|Violation Description|fine_amount| Latitude|Longitude|color long|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+----------+\n",
      "|   1103341116|2015-12-21T00:00:00|      1251|    null|       null|            CA|           200304|null|HOND|        PA|   GY|     13147 WELBY WAY|01521|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|      Gray|\n",
      "|   1103700150|2015-12-21T00:00:00|      1435|    null|       null|            CA|           201512|null| GMC|        VN|   WH|       525 S MAIN ST| 1C51|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|     White|\n",
      "|   1104803000|2015-12-21T00:00:00|      2055|    null|       null|            CA|           201503|null|NISS|        PA|   BK|       200 WORLD WAY|  2R2|     2|          8939|           WHITE CURB|         58|6439997.9|1802686.4|     Black|\n",
      "|   1104820732|2015-12-26T00:00:00|      1515|    null|       null|            CA|             null|null|ACUR|        PA|   WH|       100 WORLD WAY| 2F11|     2|           000|               17104h|       null|6440041.1|1802686.2|     White|\n",
      "|   1105461453|2015-09-15T00:00:00|       115|    null|       null|            CA|           200316|null|CHEV|        PA|   BK|  GEORGIA ST/OLYMPIC|1FB70|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|     Black|\n",
      "|   1106226590|2015-09-15T00:00:00|        19|    null|       null|            CA|           201507|null|CHEV|        VN|   GY|  SAN PEDRO S/O BOYD|1A35W|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|      Gray|\n",
      "|   1106500452|2015-12-17T00:00:00|      1710|    null|       null|            CA|           201605|null|MAZD|        PA|   BL|     SUNSET/ALVARADO|00217|     1|          8070| PARK IN GRID LOCK ZN|        163|    99999|    99999|      Blue|\n",
      "|   1106500463|2015-12-17T00:00:00|      1710|    null|       null|            CA|           201602|null|TOYO|        PA|   BK|     SUNSET/ALVARADO|00217|     1|          8070| PARK IN GRID LOCK ZN|        163|    99999|    99999|     Black|\n",
      "|   1106506402|2015-12-22T00:00:00|       945|    null|       null|            CA|           201605|null|CHEV|        PA|   BR|      721 S WESTLAKE| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|     Brown|\n",
      "|   1106506413|2015-12-22T00:00:00|      1100|    null|       null|            CA|           201701|null|NISS|        PA|   SI|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|    Silver|\n",
      "|   1106506424|2015-12-22T00:00:00|      1100|    null|       null|            CA|           201511|null|FORD|        TR|   WH|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|     White|\n",
      "|   1106506435|2015-12-22T00:00:00|      1105|    null|       null|            CA|           201701|null|CHRY|        PA|   GO|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|      Gold|\n",
      "|   1106506446|2015-12-22T00:00:00|      1110|    null|       null|            CA|           201511|null| BMW|        PA|   BK|      1200 W MIRAMAR| 2A75|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|     Black|\n",
      "|   1106549754|2015-12-15T00:00:00|       825|    null|       null|            CA|           201607|null|PTRB|        TR|   BK|           4TH/STATE| CM96|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|     Black|\n",
      "|   1107179581|2015-12-27T00:00:00|      1055|    null|       null|            CA|           201605|null|TOYO|        PA|   BK|3100 N HOLLYRIDGE DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|     Black|\n",
      "|   1107179592|2015-12-27T00:00:00|      1200|    null|       null|            CA|           201602|null|MBNZ|        PA|   BK|   3115 N BERENDO DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|     Black|\n",
      "|   1107179603|2015-12-27T00:00:00|      1400|    null|       null|            CA|           201611|null|NISS|        PA|   WH| 3100 N BEACHWOOD DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|     White|\n",
      "|   1107539823|2015-09-16T00:00:00|      2120|    null|       null|            CA|           201502|null|NISS|        PA| null|      BLAINE/11TH PL|1FB95|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|      null|\n",
      "|   1107539834|2015-09-16T00:00:00|      1045|    null|       null|            CA|             null|null|CHEV|        PA|   BK|  1246 S FIGUEROA ST| 1L20|     1|        8069AP|     NO STOP/STAND PM|         93|    99999|    99999|     Black|\n",
      "|   1107780811|2015-12-22T00:00:00|      1102|    null|       null|            CA|           201606|null|HOND|        PA|   BK|       PLATA/RAMPART|  2A1|     1|         8069B|           NO PARKING|         73|    99999|    99999|     Black|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "The schema for the data frame is the following:\n",
      "\n",
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- fine_amount: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- color long: string (nullable = true)\n",
      "\n",
      "\n",
      "\n",
      "The number of rows in the table is: 9257460\n",
      "The number of partitions of the RDD underlying the table: 10\n",
      "\n",
      "The maximum fine reported was 98.0\n",
      "with a total of 184 rows matching such fine amount\n",
      "\n",
      "The most reported makes are as follows:\n",
      "+----+-------+\n",
      "|Make|  count|\n",
      "+----+-------+\n",
      "|TOYT|1531949|\n",
      "|HOND|1043276|\n",
      "|FORD| 807498|\n",
      "|NISS| 662097|\n",
      "|CHEV| 631413|\n",
      "| BMW| 422916|\n",
      "|MERZ| 376830|\n",
      "|VOLK| 316002|\n",
      "|HYUN| 285286|\n",
      "|DODG| 271590|\n",
      "|LEXS| 263269|\n",
      "| KIA| 217795|\n",
      "|JEEP| 214965|\n",
      "|AUDI| 179718|\n",
      "|MAZD| 169811|\n",
      "|OTHR| 154376|\n",
      "| GMC| 132788|\n",
      "|INFI| 120340|\n",
      "|CHRY| 120317|\n",
      "|ACUR| 111265|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "The most common color of reported Toyotas was:\n",
      "+----------+------+\n",
      "|color long| count|\n",
      "+----------+------+\n",
      "|      Gray|346822|\n",
      "+----------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()\n",
    "\n",
    "print(f\"The schema for the data frame is the following:\\n\")\n",
    "data.printSchema()\n",
    "\n",
    "num_rows_df = data.count()\n",
    "num_part_df = data.rdd.getNumPartitions()\n",
    "print(f\"\\n\\nThe number of rows in the table is: {num_rows_df}\\n\"\n",
    "    f\"The number of partitions of the RDD underlying the table: {num_part_df}\\n\")\n",
    "\n",
    "data.drop('VIN')\n",
    "data.drop('Latitude')\n",
    "data.drop('Longitude')\n",
    "\n",
    "data = data.withColumnRenamed(\"Fine amount\", \"fine_amount\") # Remove cancerous white spaces\n",
    "\n",
    "max_fine = data\\\n",
    "    .agg({\"fine_amount\": \"max\"})\\\n",
    "    .collect()[0]\n",
    "\n",
    "rows_max_fine = data\\\n",
    "    .filter(data.fine_amount == max_fine['max(fine_amount)'])\\\n",
    "    .count()\n",
    "    \n",
    "print(f\"The maximum fine reported was {max_fine['max(fine_amount)']}\\n\"\n",
    "      f\"with a total of {rows_max_fine} rows matching such fine amount\\n\")\n",
    "\n",
    "make_freq = data\\\n",
    "    .groupby('Make')\\\n",
    "    .count()\n",
    "\n",
    "print(f\"The most reported makes are as follows:\")\n",
    "make_freq.orderBy(make_freq['count'].desc()).show(20)\n",
    "\n",
    "\n",
    "def color_exp(short):\n",
    "    \"\"\"Extends color if it exists in the register\"\"\"\n",
    "    COLORS = {\n",
    "    'AL':'Aluminum', 'AM':'Amber', 'BG':'Beige', 'BK':'Black',\n",
    "    'BL':'Blue', 'BN':'Brown', 'BR':'Brown', 'BZ':'Bronze',\n",
    "    'CH':'Charcoal', 'DK':'Dark', 'GD':'Gold', 'GO':'Gold',\n",
    "    'GN':'Green', 'GY':'Gray', 'GT':'Granite', 'IV':'Ivory',\n",
    "    'LT':'Light', 'OL':'Olive', 'OR':'Orange', 'MR':'Maroon',\n",
    "    'PK':'Pink', 'RD':'Red', 'RE':'Red', 'SI':'Silver', 'SL':'Silver',\n",
    "    'SM':'Smoke', 'TN':'Tan', 'VT':'Violet', 'WT':'White',\n",
    "    'WH':'White', 'YL':'Yellow', 'YE':'Yellow', 'UN':'Unknown'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        COLORS[short]\n",
    "    except KeyError:\n",
    "        return short\n",
    "    return COLORS[short]\n",
    "color_udf = F.udf(lambda x: color_exp(x), StringType())\n",
    "data = data.withColumn(\"color long\", color_udf(data.Color))\n",
    "\n",
    "toyotas = data.filter(data.Make == 'TOYT')\n",
    "toy_freq_colors = toyotas.groupBy('color long').count()\n",
    "\n",
    "print(f\"The most common color of reported Toyotas was:\")\n",
    "toy_freq_colors.orderBy(toy_freq_colors['count'].desc()).show(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
